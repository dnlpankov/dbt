[0m22:56:07.621998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73E4F9AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABDC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABC70>]}


============================== 22:56:07.739088 | e658d13a-3aea-45ae-96c8-380c5b933b1f ==============================
[0m22:56:07.739088 [info ] [MainThread]: Running with dbt=1.7.11
[0m22:56:07.760077 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'quiet': 'False', 'write_json': 'True', 'use_colors': 'True', 'invocation_command': 'dbt init', 'fail_fast': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_format': 'default', 'debug': 'False', 'partial_parse': 'True', 'target_path': 'None'}
[0m22:56:07.774041 [warn ] [MainThread]: [ConfigFolderDirectory]: Unable to parse dict {'dir': WindowsPath('C:/Users/Danila/.dbt')}
[0m22:56:07.774997 [info ] [MainThread]: Creating dbt configuration folder at 
[0m22:56:51.233243 [debug] [MainThread]: Starter project path: D:\Users\Danila\anaconda3\envs\dbt_env\lib\site-packages\dbt\include\starter_project
[0m22:56:51.541752 [info ] [MainThread]: 
Your new dbt project "campaign_performance" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m22:56:51.542948 [info ] [MainThread]: Setting up your profile.
[0m23:05:35.210962 [info ] [MainThread]: Profile campaign_performance written to C:\Users\Danila\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m23:05:35.626903 [debug] [MainThread]: Command `dbt init` succeeded at 23:05:35.258368 after 567.86 seconds
[0m23:05:35.672312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73E4F9AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABB80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABCD0>]}
[0m23:05:35.708216 [debug] [MainThread]: Flushing usage events
[0m23:15:15.432463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D63469D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C820>]}


============================== 23:15:15.573512 | 61319262-bf15-452b-a2d5-9e67fe184b2b ==============================
[0m23:15:15.573512 [info ] [MainThread]: Running with dbt=1.7.11
[0m23:15:15.604971 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'log_format': 'default', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'cache_selected_only': 'False', 'debug': 'False', 'printer_width': '80', 'warn_error': 'None', 'indirect_selection': 'eager', 'static_parser': 'True', 'invocation_command': 'dbt test', 'quiet': 'False', 'fail_fast': 'False'}
[0m23:15:15.631123 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m23:15:15.683477 [debug] [MainThread]: Command `dbt test` failed at 23:15:15.634122 after 0.40 seconds
[0m23:15:15.684472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D63469D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2CD60>]}
[0m23:15:15.688463 [debug] [MainThread]: Flushing usage events
[0m01:12:41.668518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA6DF6AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA5F9A0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DDA00>]}


============================== 01:12:41.786091 | 1d747f0f-2e9f-4533-b232-cb7d88e2ca7d ==============================
[0m01:12:41.786091 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:12:41.806607 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'debug': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'introspect': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'no_print': 'None', 'printer_width': '80', 'quiet': 'False', 'fail_fast': 'False', 'log_path': 'logs'}
[0m01:12:41.808604 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m01:12:41.829961 [debug] [MainThread]: Command `dbt run` failed at 01:12:41.810604 after 0.31 seconds
[0m01:12:41.830960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA6DF6AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DD490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DD5E0>]}
[0m01:12:41.831958 [debug] [MainThread]: Flushing usage events
[0m01:13:05.616119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418E031A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000241904667F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D9A0>]}


============================== 01:13:05.619147 | ced84743-8c0c-4886-a8f2-13495d16fd33 ==============================
[0m01:13:05.619147 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:13:05.621104 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'target_path': 'None', 'log_cache_events': 'False', 'warn_error': 'None', 'log_format': 'default', 'fail_fast': 'False', 'log_path': 'logs', 'write_json': 'True', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'partial_parse': 'True', 'debug': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'invocation_command': 'dbt run', 'printer_width': '80', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'use_colors': 'True'}
[0m01:13:05.784488 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m01:13:05.792792 [debug] [MainThread]: Command `dbt run` failed at 01:13:05.791806 after 0.26 seconds
[0m01:13:05.795750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418E031A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D190>]}
[0m01:13:05.798743 [debug] [MainThread]: Flushing usage events
[0m22:27:09.431445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105991f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f23d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f2a90>]}


============================== 22:27:09.433023 | 498f5558-7911-4fbb-b56d-65eed82ab48f ==============================
[0m22:27:09.433023 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:27:09.433342 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'version_check': 'True', 'introspect': 'True', 'log_format': 'default', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'quiet': 'False', 'static_parser': 'True', 'debug': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'write_json': 'True', 'use_colors': 'True', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'target_path': 'None'}
[0m22:27:09.499429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059cdb90>]}
[0m22:27:09.529467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c8990>]}
[0m22:27:09.530170 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m22:27:09.537501 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:27:09.555599 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:27:09.555842 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:27:09.556321 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m22:27:09.558974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105979a10>]}
[0m22:27:09.564032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106044e90>]}
[0m22:27:09.564291 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m22:27:09.564472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061bbed0>]}
[0m22:27:09.565511 [info ] [MainThread]: 
[0m22:27:09.565882 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:27:09.566597 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:27:09.570892 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:27:09.571081 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:27:09.571240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:27:10.030199 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m22:27:10.034852 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:27:10.038907 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:27:10.048096 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:27:10.048758 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:27:10.049098 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:27:10.394963 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.397244 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:27:10.398436 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m22:27:10.441925 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m22:27:10.446698 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:27:10.506304 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:27:10.523310 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.523779 [debug] [MainThread]: On master: BEGIN
[0m22:27:10.524242 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:27:10.783865 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.784930 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.785553 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:27:10.827627 [debug] [MainThread]: SQL status: SELECT 47 in 0.0 seconds
[0m22:27:10.834200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fab0d0>]}
[0m22:27:10.835227 [debug] [MainThread]: On master: ROLLBACK
[0m22:27:10.866107 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.867503 [debug] [MainThread]: On master: BEGIN
[0m22:27:10.929870 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.931303 [debug] [MainThread]: On master: COMMIT
[0m22:27:10.932480 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.933570 [debug] [MainThread]: On master: COMMIT
[0m22:27:10.964373 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:27:10.965807 [debug] [MainThread]: On master: Close
[0m22:27:10.968224 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:27:10.968965 [info ] [MainThread]: 
[0m22:27:10.974877 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m22:27:10.975770 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m22:27:10.976963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m22:27:10.977531 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m22:27:10.991359 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:10.992510 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 22:27:10.977902 => 22:27:10.992250
[0m22:27:10.992913 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m22:27:11.018801 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.019386 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.019620 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m22:27:11.019832 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:11.490323 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:11.492501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.494195 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m22:27:36.140173 [debug] [Thread-1 (]: SQL status: SELECT 2110 in 25.0 seconds
[0m22:27:36.153822 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.154661 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m22:27:36.198635 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.205893 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.206616 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m22:27:36.250434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.279251 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m22:27:36.279807 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.280166 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m22:27:36.323367 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:36.329861 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m22:27:36.334102 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.334465 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m22:27:36.389864 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:36.391886 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 22:27:10.993127 => 22:27:36.391596
[0m22:27:36.392422 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m22:27:36.393596 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f71d10>]}
[0m22:27:36.394376 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2110[0m in 25.42s]
[0m22:27:36.395106 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m22:27:36.395638 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m22:27:36.396264 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m22:27:36.397000 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m22:27:36.397389 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m22:27:36.400382 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m22:27:36.401215 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 22:27:36.397655 => 22:27:36.400990
[0m22:27:36.401600 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m22:27:36.405512 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m22:27:36.406166 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.406484 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m22:27:36.406791 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:36.752487 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:36.753172 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.753701 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m22:27:36.802391 [debug] [Thread-1 (]: SQL status: SELECT 1442 in 0.0 seconds
[0m22:27:36.809155 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.809888 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m22:27:36.841758 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.848824 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.849676 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m22:27:36.881765 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.887442 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m22:27:36.888156 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.888757 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m22:27:36.920643 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:36.930397 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m22:27:36.931937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.932588 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m22:27:36.984267 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:36.985947 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 22:27:36.401835 => 22:27:36.985740
[0m22:27:36.986343 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m22:27:36.987346 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10627db50>]}
[0m22:27:36.987902 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1442[0m in 0.59s]
[0m22:27:36.988370 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m22:27:36.988705 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.989150 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m22:27:36.989812 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m22:27:36.990147 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.992671 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.993349 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 22:27:36.990333 => 22:27:36.993180
[0m22:27:36.993656 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.996816 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.997273 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.997523 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m22:27:36.997755 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:37.749776 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:27:37.750496 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.750943 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m22:27:37.810303 [debug] [Thread-1 (]: SQL status: SELECT 1442 in 0.0 seconds
[0m22:27:37.815932 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.816533 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m22:27:37.856775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:37.862846 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.863490 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m22:27:37.903660 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:37.908087 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m22:27:37.908799 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.909560 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m22:27:37.950714 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:37.957719 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m22:27:37.959572 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.960324 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m22:27:38.018347 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:38.022183 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 22:27:36.993837 => 22:27:38.021744
[0m22:27:38.023082 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m22:27:38.025207 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106292f10>]}
[0m22:27:38.026223 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1442[0m in 1.04s]
[0m22:27:38.027144 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m22:27:38.027882 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m22:27:38.028676 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m22:27:38.029613 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m22:27:38.030103 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m22:27:38.035094 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m22:27:38.036202 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 22:27:38.030390 => 22:27:38.035933
[0m22:27:38.036638 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m22:27:38.041364 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m22:27:38.042086 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.042406 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m22:27:38.042708 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:38.395142 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:38.396538 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.397451 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m22:27:38.448016 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m22:27:38.457384 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.458069 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m22:27:38.501335 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:38.508761 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.509412 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m22:27:38.552608 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:38.558811 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m22:27:38.559593 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.560292 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m22:27:38.603016 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:38.608975 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m22:27:38.610388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.610990 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m22:27:38.674369 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:38.679053 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 22:27:38.036899 => 22:27:38.678596
[0m22:27:38.679866 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m22:27:38.681755 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106219310>]}
[0m22:27:38.682761 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.65s]
[0m22:27:38.683643 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m22:27:38.684297 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.685285 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m22:27:38.686273 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m22:27:38.686751 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.691324 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.692365 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 22:27:38.687048 => 22:27:38.692083
[0m22:27:38.692836 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.699634 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.700297 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.700616 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m22:27:38.700921 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:38.958826 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:38.960690 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.961627 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:27:38.996621 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m22:27:39.005573 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.006424 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:27:39.039001 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:39.046848 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.047816 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:27:39.080223 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:39.085020 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m22:27:39.085869 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.086442 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m22:27:39.116866 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:39.124271 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m22:27:39.126016 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.126791 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m22:27:39.175824 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:39.180214 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 22:27:38.693123 => 22:27:39.179792
[0m22:27:39.180995 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m22:27:39.182621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062cd390>]}
[0m22:27:39.183549 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.50s]
[0m22:27:39.184420 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m22:27:39.185098 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.186032 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m22:27:39.187033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:27:39.187511 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.194169 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.195111 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:27:39.187816 => 22:27:39.194881
[0m22:27:39.195512 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.199733 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.200271 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.200597 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:27:39.200909 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:39.561948 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:39.563388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.564503 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
  );
  
[0m22:27:48.970380 [debug] [Thread-1 (]: SQL status: SELECT 143735 in 9.0 seconds
[0m22:27:48.979568 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:48.980462 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:27:49.025107 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:49.032166 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.032851 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:27:49.077241 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:49.080983 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:27:49.081646 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.082198 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:27:49.127129 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:49.134047 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m22:27:49.135304 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.135818 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:27:49.195903 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:49.200151 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:27:39.195756 => 22:27:49.199740
[0m22:27:49.201052 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:27:49.203040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b16d0>]}
[0m22:27:49.204196 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 143735[0m in 10.02s]
[0m22:27:49.205341 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:49.206233 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.207200 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m22:27:49.208240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:27:49.208795 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.215458 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.217016 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:27:49.209117 => 22:27:49.216675
[0m22:27:49.217565 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.222502 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.223301 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.223686 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:27:49.224060 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:49.503377 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:49.505435 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.506533 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2023-12-31' --matomo
    group by day, country_code, campaign_name, ga_campaign_name
  );
  
[0m22:27:54.396656 [debug] [Thread-1 (]: SQL status: SELECT 39884 in 5.0 seconds
[0m22:27:54.404128 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.404808 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:27:54.438311 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:54.443205 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:27:54.444016 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.444715 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:27:54.478406 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:54.488162 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m22:27:54.489292 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.489777 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:27:54.544836 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:54.549017 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:27:49.217868 => 22:27:54.548622
[0m22:27:54.549782 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:27:54.551605 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10628af10>]}
[0m22:27:54.552547 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 39884[0m in 5.34s]
[0m22:27:54.553384 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:27:54.554048 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m22:27:54.554844 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m22:27:54.555949 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m22:27:54.556455 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m22:27:54.561518 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m22:27:54.562834 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 22:27:54.556780 => 22:27:54.562536
[0m22:27:54.563335 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m22:27:54.579594 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m22:27:54.580232 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:54.580517 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m22:27:54.580783 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:54.953823 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:54.955952 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:54.956853 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m22:27:54.992211 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:27:55.000558 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.001196 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m22:27:55.032479 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.038158 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.038921 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m22:27:55.070505 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.074660 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m22:27:55.075274 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.075784 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m22:27:55.106482 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:55.112418 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m22:27:55.118306 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.118858 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m22:27:55.150298 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:27:55.153524 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 22:27:54.563621 => 22:27:55.152911
[0m22:27:55.154354 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m22:27:55.156298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062886d0>]}
[0m22:27:55.157407 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.60s]
[0m22:27:55.158535 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m22:27:55.159381 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m22:27:55.160222 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m22:27:55.161196 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m22:27:55.161747 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m22:27:55.166048 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m22:27:55.167873 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 22:27:55.162105 => 22:27:55.167232
[0m22:27:55.168544 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m22:27:55.174169 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m22:27:55.174943 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.175328 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m22:27:55.175700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:55.429467 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:55.431706 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.432901 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m22:27:55.467155 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:27:55.475750 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.476403 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m22:27:55.507789 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.514638 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.515417 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m22:27:55.546692 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.552879 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m22:27:55.553525 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.554020 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m22:27:55.584809 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:55.589659 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m22:27:55.590796 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.591731 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m22:27:55.639605 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:55.642923 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 22:27:55.168864 => 22:27:55.642495
[0m22:27:55.643815 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m22:27:55.645779 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060925d0>]}
[0m22:27:55.646976 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.48s]
[0m22:27:55.647868 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m22:27:55.648558 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m22:27:55.649333 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m22:27:55.650341 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m22:27:55.650891 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m22:27:55.656342 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.657570 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 22:27:55.651213 => 22:27:55.657270
[0m22:27:55.658074 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m22:27:55.701483 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.702086 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.702298 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m22:27:55.702484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:55.956890 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:55.958644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.959516 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m22:27:56.560323 [debug] [Thread-1 (]: SQL status: SELECT 55542 in 1.0 seconds
[0m22:27:56.568384 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.569031 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m22:27:56.599768 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:56.605821 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.606436 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m22:27:56.637886 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:56.642342 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m22:27:56.643105 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.643798 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m22:27:56.675719 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:56.682573 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m22:27:56.684150 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.684704 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m22:27:56.732900 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:56.736683 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 22:27:55.658359 => 22:27:56.736245
[0m22:27:56.737493 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m22:27:56.739385 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105023b10>]}
[0m22:27:56.740560 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 55542[0m in 1.09s]
[0m22:27:56.741677 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m22:27:56.742605 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.743739 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m22:27:56.744750 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m22:27:56.745292 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.750222 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.751620 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 22:27:56.745629 => 22:27:56.751370
[0m22:27:56.752461 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.758093 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.759054 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.759444 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m22:27:56.759801 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:57.012525 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:57.014534 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.015326 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m22:27:57.049577 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:27:57.057609 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.058294 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:27:57.090077 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.094153 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m22:27:57.095088 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.095823 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m22:27:57.126762 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:57.130333 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m22:27:57.131296 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.131708 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m22:27:57.162380 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:27:57.165101 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 22:27:56.752775 => 22:27:57.164791
[0m22:27:57.165699 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m22:27:57.167269 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062938d0>]}
[0m22:27:57.168067 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.42s]
[0m22:27:57.168792 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m22:27:57.169318 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.169837 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m22:27:57.170773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m22:27:57.171264 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.174971 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.175936 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 22:27:57.171524 => 22:27:57.175686
[0m22:27:57.176340 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.180232 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.180820 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.181142 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m22:27:57.181442 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:57.538668 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:57.540802 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.541953 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m22:27:57.614303 [debug] [Thread-1 (]: SQL status: SELECT 64 in 0.0 seconds
[0m22:27:57.623154 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.623855 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m22:27:57.667648 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.674181 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.674801 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m22:27:57.718255 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.724088 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m22:27:57.724878 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.725488 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m22:27:57.769695 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:57.779761 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m22:27:57.781024 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.781481 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m22:27:57.841645 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:57.845896 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 22:27:57.176573 => 22:27:57.845491
[0m22:27:57.846658 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m22:27:57.848219 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106268d90>]}
[0m22:27:57.849090 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 64[0m in 0.68s]
[0m22:27:57.849855 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.851935 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:57.852369 [debug] [MainThread]: On master: BEGIN
[0m22:27:57.852738 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:27:58.137308 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:58.139581 [debug] [MainThread]: On master: COMMIT
[0m22:27:58.140891 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:58.141547 [debug] [MainThread]: On master: COMMIT
[0m22:27:58.175882 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:27:58.177329 [debug] [MainThread]: On master: Close
[0m22:27:58.180189 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:27:58.180783 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m22:27:58.181570 [info ] [MainThread]: 
[0m22:27:58.182466 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 48.62 seconds (48.62s).
[0m22:27:58.185794 [debug] [MainThread]: Command end result
[0m22:27:58.198322 [info ] [MainThread]: 
[0m22:27:58.198913 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:27:58.199276 [info ] [MainThread]: 
[0m22:27:58.199651 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m22:27:58.201977 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 48.805172, "process_user_time": 1.794044, "process_kernel_time": 0.182757, "process_mem_max_rss": "126418944", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:27:58.202496 [debug] [MainThread]: Command `dbt run` succeeded at 22:27:58.202384 after 48.81 seconds
[0m22:27:58.202844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f1650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1012fdf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101238850>]}
[0m22:27:58.203180 [debug] [MainThread]: Flushing usage events
[0m11:29:27.824869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109947450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099be010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099be690>]}


============================== 11:29:27.826720 | 7a3f9496-6a36-43cd-b22b-d360356d14b7 ==============================
[0m11:29:27.826720 [info ] [MainThread]: Running with dbt=1.7.0
[0m11:29:27.827110 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'no_print': 'None', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'use_colors': 'True', 'debug': 'False', 'target_path': 'None', 'quiet': 'False', 'printer_width': '80', 'warn_error': 'None', 'partial_parse': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'fail_fast': 'False', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'indirect_selection': 'eager'}
[0m11:29:27.900579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a80d510>]}
[0m11:29:27.930763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e67650>]}
[0m11:29:27.931151 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m11:29:27.938707 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m11:29:27.959472 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:29:27.959731 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:29:27.960186 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m11:29:27.962766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e9eb90>]}
[0m11:29:27.969266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa37fd0>]}
[0m11:29:27.969493 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m11:29:27.969673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a819750>]}
[0m11:29:27.970675 [info ] [MainThread]: 
[0m11:29:27.971065 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:29:27.971771 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m11:29:27.976589 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m11:29:27.976854 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m11:29:27.977151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:28.309454 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m11:29:28.313475 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m11:29:28.318370 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m11:29:28.327934 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m11:29:28.328530 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m11:29:28.328955 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:29:28.688080 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:29:28.689890 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m11:29:28.691385 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m11:29:28.758382 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m11:29:28.764126 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m11:29:28.806919 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m11:29:28.823788 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:28.824530 [debug] [MainThread]: On master: BEGIN
[0m11:29:28.825007 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:29:29.154978 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.157369 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.158729 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:29:29.208972 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m11:29:29.213748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109944fd0>]}
[0m11:29:29.214763 [debug] [MainThread]: On master: ROLLBACK
[0m11:29:29.253883 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.254823 [debug] [MainThread]: On master: BEGIN
[0m11:29:29.332746 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.334415 [debug] [MainThread]: On master: COMMIT
[0m11:29:29.335703 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.336397 [debug] [MainThread]: On master: COMMIT
[0m11:29:29.375648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:29:29.377049 [debug] [MainThread]: On master: Close
[0m11:29:29.380195 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:29:29.381272 [info ] [MainThread]: 
[0m11:29:29.387196 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.388055 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m11:29:29.389084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m11:29:29.389791 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.402061 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.403341 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 11:29:29.390202 => 11:29:29.403100
[0m11:29:29.403725 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.428342 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.429320 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.429568 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m11:29:29.429788 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:29.683814 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.685975 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.687759 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m11:29:56.189010 [debug] [Thread-1 (]: SQL status: SELECT 2111 in 26.0 seconds
[0m11:29:56.202850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.203719 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m11:29:56.260397 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.269071 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.269901 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m11:29:56.301182 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.336736 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m11:29:56.337480 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.337981 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m11:29:56.369530 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:56.380629 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m11:29:56.386373 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.386885 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m11:29:56.431511 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:56.435743 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 11:29:29.403937 => 11:29:56.435150
[0m11:29:56.436835 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m11:29:56.438869 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa93890>]}
[0m11:29:56.440068 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2111[0m in 27.05s]
[0m11:29:56.441285 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m11:29:56.442166 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m11:29:56.443411 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m11:29:56.444697 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m11:29:56.445304 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m11:29:56.449939 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m11:29:56.452731 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 11:29:56.445689 => 11:29:56.452366
[0m11:29:56.453278 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m11:29:56.458949 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m11:29:56.459970 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.460395 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m11:29:56.460766 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:56.834919 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:56.837210 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.837984 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m11:29:56.886982 [debug] [Thread-1 (]: SQL status: SELECT 1473 in 0.0 seconds
[0m11:29:56.894810 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.895420 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m11:29:56.929220 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.934831 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.935404 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m11:29:56.968533 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.972961 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m11:29:56.974360 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.974893 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m11:29:57.008795 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:57.022097 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m11:29:57.023822 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:57.024770 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m11:29:57.079088 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:57.084269 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 11:29:56.453603 => 11:29:57.083920
[0m11:29:57.084985 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m11:29:57.087428 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac4fbd0>]}
[0m11:29:57.088417 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1473[0m in 0.64s]
[0m11:29:57.089710 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m11:29:57.091069 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.091808 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m11:29:57.093018 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m11:29:57.093886 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.098944 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.099975 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 11:29:57.094520 => 11:29:57.099723
[0m11:29:57.100549 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.106875 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.108709 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.109251 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m11:29:57.109741 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:57.417280 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:57.419062 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.420479 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m11:29:57.481452 [debug] [Thread-1 (]: SQL status: SELECT 1473 in 0.0 seconds
[0m11:29:57.484991 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.485417 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m11:29:57.522643 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:57.524151 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.524332 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m11:29:57.560942 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:57.563484 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m11:29:57.563969 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.564375 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m11:29:57.601034 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:57.606092 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m11:29:57.607644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.608317 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m11:29:57.666246 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:57.670418 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 11:29:57.100920 => 11:29:57.669580
[0m11:29:57.671877 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m11:29:57.675042 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac5cf10>]}
[0m11:29:57.676689 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1473[0m in 0.58s]
[0m11:29:57.678217 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.679641 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m11:29:57.680788 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m11:29:57.682097 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m11:29:57.682782 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m11:29:57.688100 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m11:29:57.689822 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 11:29:57.683230 => 11:29:57.689459
[0m11:29:57.690599 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m11:29:57.696860 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m11:29:57.697795 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:57.698020 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m11:29:57.698234 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:57.977130 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:57.978604 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:57.979396 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m11:29:58.017308 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m11:29:58.027390 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.028262 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m11:29:58.060659 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.072085 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.073204 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m11:29:58.104931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.108959 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m11:29:58.109580 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.110320 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m11:29:58.141092 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:58.147300 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m11:29:58.149547 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.150426 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m11:29:58.200278 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:58.204063 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 11:29:57.690967 => 11:29:58.203646
[0m11:29:58.204808 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m11:29:58.207595 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac24110>]}
[0m11:29:58.208700 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.53s]
[0m11:29:58.210162 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m11:29:58.211228 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.212446 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m11:29:58.215020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m11:29:58.216323 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.221734 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.223560 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 11:29:58.216756 => 11:29:58.223150
[0m11:29:58.224310 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.236054 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.237015 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.237478 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m11:29:58.237906 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:58.513810 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:58.515859 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.517408 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m11:29:58.555230 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m11:29:58.568101 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.569718 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m11:29:58.603968 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.613631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.614789 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m11:29:58.649645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.655279 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m11:29:58.656759 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.658095 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m11:29:58.692407 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:58.702810 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m11:29:58.706053 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.707263 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m11:29:58.760056 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:58.765608 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 11:29:58.224760 => 11:29:58.764851
[0m11:29:58.767134 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m11:29:58.770743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac7af10>]}
[0m11:29:58.771825 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.56s]
[0m11:29:58.772771 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.773806 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.775139 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m11:29:58.776753 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m11:29:58.777554 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.786247 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.788272 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 11:29:58.777979 => 11:29:58.787805
[0m11:29:58.788967 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.796147 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.797305 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.797832 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m11:29:58.798306 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:59.119924 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:59.121186 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:59.122231 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m11:30:08.887801 [debug] [Thread-1 (]: SQL status: SELECT 153021 in 10.0 seconds
[0m11:30:08.894791 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.895469 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m11:30:08.935243 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:08.942405 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.943125 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m11:30:08.983043 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:08.987700 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m11:30:08.988536 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.989229 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m11:30:09.028142 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:09.033859 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m11:30:09.035545 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:09.036152 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m11:30:09.092780 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:09.096194 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 11:29:58.789466 => 11:30:09.095875
[0m11:30:09.097181 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m11:30:09.099503 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac98510>]}
[0m11:30:09.100722 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153021[0m in 10.32s]
[0m11:30:09.101881 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m11:30:09.102791 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.103771 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m11:30:09.105221 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m11:30:09.106054 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.113080 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.114843 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 11:30:09.106480 => 11:30:09.114415
[0m11:30:09.115643 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.122562 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.123807 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.124308 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m11:30:09.124834 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:09.407733 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:09.409736 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.411659 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m11:30:14.314088 [debug] [Thread-1 (]: SQL status: SELECT 45760 in 5.0 seconds
[0m11:30:14.321838 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.322711 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m11:30:14.354506 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.365802 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.366362 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m11:30:14.397524 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.403253 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m11:30:14.403876 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.404359 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m11:30:14.435499 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:14.442024 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m11:30:14.443479 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.444451 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m11:30:14.491125 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:14.494592 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 11:30:09.116217 => 11:30:14.494296
[0m11:30:14.495263 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m11:30:14.497559 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa82510>]}
[0m11:30:14.498469 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45760[0m in 5.39s]
[0m11:30:14.500028 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m11:30:14.501182 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m11:30:14.502162 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m11:30:14.504074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m11:30:14.504956 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m11:30:14.511300 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m11:30:14.513079 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 11:30:14.505345 => 11:30:14.512750
[0m11:30:14.513693 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m11:30:14.537425 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m11:30:14.538501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.538921 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m11:30:14.539276 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:14.795907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:14.797576 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.798894 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m11:30:14.834301 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m11:30:14.842027 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.842807 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m11:30:14.874751 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.883465 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.884292 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m11:30:14.916070 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.921521 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m11:30:14.922408 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.923107 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m11:30:14.954788 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:14.960990 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m11:30:14.968663 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.969519 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m11:30:15.075894 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m11:30:15.080825 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 11:30:14.514072 => 11:30:15.080267
[0m11:30:15.081979 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m11:30:15.083855 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac6e510>]}
[0m11:30:15.085452 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.58s]
[0m11:30:15.087215 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m11:30:15.088098 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m11:30:15.089206 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m11:30:15.090669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m11:30:15.091213 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m11:30:15.096344 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m11:30:15.098885 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 11:30:15.091465 => 11:30:15.098359
[0m11:30:15.099770 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m11:30:15.107568 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m11:30:15.109042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.109721 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m11:30:15.110231 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:15.490905 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:15.492533 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.493936 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m11:30:15.527561 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:30:15.537596 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.538458 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m11:30:15.570592 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:15.577545 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.578667 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m11:30:15.609718 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:15.618308 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m11:30:15.619711 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.620661 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m11:30:15.651696 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:15.666560 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m11:30:15.668994 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.670033 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m11:30:15.717891 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:15.722520 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 11:30:15.100140 => 11:30:15.721782
[0m11:30:15.723918 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m11:30:15.727056 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8891d0>]}
[0m11:30:15.729367 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.64s]
[0m11:30:15.730950 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m11:30:15.732126 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m11:30:15.733601 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m11:30:15.735032 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m11:30:15.735959 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m11:30:15.742502 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.745186 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 11:30:15.736663 => 11:30:15.744833
[0m11:30:15.745824 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m11:30:15.796031 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.796727 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.796954 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m11:30:15.797157 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:16.054991 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:16.056443 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.057178 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m11:30:16.330722 [debug] [Thread-1 (]: SQL status: SELECT 56297 in 0.0 seconds
[0m11:30:16.339403 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.340765 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m11:30:16.372645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.382747 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.383850 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m11:30:16.415893 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.423753 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m11:30:16.425267 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.426648 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m11:30:16.458904 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:16.468553 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m11:30:16.470814 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.471805 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m11:30:16.523724 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:16.527865 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 11:30:15.746211 => 11:30:16.527511
[0m11:30:16.528500 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m11:30:16.530006 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac796d0>]}
[0m11:30:16.531645 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 56297[0m in 0.80s]
[0m11:30:16.533671 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m11:30:16.535189 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.536237 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m11:30:16.537800 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m11:30:16.538626 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.543714 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.545302 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 11:30:16.539048 => 11:30:16.544993
[0m11:30:16.545927 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.553004 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.554631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.555163 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m11:30:16.555949 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:16.813202 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:16.815419 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.816669 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m11:30:16.851753 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m11:30:16.860310 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.861202 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m11:30:16.892612 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.896878 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m11:30:16.898342 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.899444 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m11:30:16.930847 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:16.937237 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m11:30:16.939156 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.940478 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m11:30:16.972299 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m11:30:16.976486 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 11:30:16.546335 => 11:30:16.976003
[0m11:30:16.977345 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m11:30:16.979786 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac8d3d0>]}
[0m11:30:16.980930 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.44s]
[0m11:30:16.982531 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.983550 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m11:30:16.984573 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m11:30:16.986027 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m11:30:16.987027 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m11:30:16.992992 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:16.994533 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 11:30:16.987564 => 11:30:16.994215
[0m11:30:16.995116 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m11:30:17.001230 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.002753 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.003264 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m11:30:17.003721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:17.332084 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:17.333369 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.334568 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m11:30:17.402329 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m11:30:17.412270 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.413050 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m11:30:17.453306 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:17.463483 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.464506 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m11:30:17.504569 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:17.510484 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m11:30:17.511415 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.512121 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m11:30:17.552547 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:17.558917 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m11:30:17.560996 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.562252 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m11:30:17.619876 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:17.624823 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 11:30:16.995503 => 11:30:17.624118
[0m11:30:17.626071 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m11:30:17.628856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acba690>]}
[0m11:30:17.630384 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.64s]
[0m11:30:17.632120 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m11:30:17.635763 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:17.636759 [debug] [MainThread]: On master: BEGIN
[0m11:30:17.637677 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:30:17.892995 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:30:17.894611 [debug] [MainThread]: On master: COMMIT
[0m11:30:17.895784 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:17.896466 [debug] [MainThread]: On master: COMMIT
[0m11:30:17.926850 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:30:17.927704 [debug] [MainThread]: On master: Close
[0m11:30:17.929878 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:30:17.930894 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m11:30:17.931790 [info ] [MainThread]: 
[0m11:30:17.932743 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 49.96 seconds (49.96s).
[0m11:30:17.938161 [debug] [MainThread]: Command end result
[0m11:30:17.959081 [info ] [MainThread]: 
[0m11:30:17.959858 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:30:17.960319 [info ] [MainThread]: 
[0m11:30:17.960790 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m11:30:17.963604 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 50.16285, "process_user_time": 1.989993, "process_kernel_time": 0.227356, "process_mem_max_rss": "126500864", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m11:30:17.964431 [debug] [MainThread]: Command `dbt run` succeeded at 11:30:17.964254 after 50.16 seconds
[0m11:30:17.964921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047e0850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ec5250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048a5f50>]}
[0m11:30:17.965442 [debug] [MainThread]: Flushing usage events
